\documentclass{Academic}
\usepackage{csquotes}
\usepackage{algorithm}
\usepackage{algpseudocode}

\addbibresource{references.bib}

\begin{document}
%Easy customisation of title page
%TC:ignore
    \myabstract{\include{abstract}}
    \renewcommand{\myTitle}{Hybrid Recommender Models in E-Learning: A Comprehensive Review of HybridBERT4Rec}
    \renewcommand{\MyAuthor}{Leon Knorr}
    \renewcommand{\MyDepartment}{Mannheim Master of Datascience}
    \renewcommand{\ID}{1902854}
    \renewcommand{\Keywords}{Education, AI, E-Learning}
    \maketitle
%\vspace{-1.9em}\noindent\rule{\textwidth}{1pt} %add this line if not using abstract
    %\onehalfspacing
%TC:endignore

    \section{Introduction}
    In the dynamic landscape of today's knowledge-driven society and global economics, the concept of life-long learning has evolved into a cornerstone for personal and professional development. It ensures the competitiveness of individuals in a globalized market, while also aiding in overcoming social challenges, such as demographic change, social cohesion or public health through continuous education. Because of its key-role in overcoming today's challenges, many governments and corporations invested heavily in lifelong learning offerings and frameworks \cite{rubensonAdultLearningEducation2011}. This investment can be seen by observing the vast landscape of different learning platforms, which have emerged over the last couple of years, ranging from publicly funded E-Learning solutions such as Moodle\cite{StartseiteMoodleOrg} or ILIAS\cite{Ilias}, to private corporate platforms such as Linked-In Learning\cite{LinkedInLearningMit}. As individuals embark on continuous learning journeys on such platforms, the demand for tailored educational experiences has surged. These experiences not only include the recommendation of new content, but also content which aims to aid the user with current learning objectives. Recommender algorithms play a pivotal role in shaping these learning odysseys by providing personalized content recommendations \cite{jeevamolOntologybasedHybridElearning2021}. \\
    In this work, the hybrid content recommendation system HybridBERT4Rec, which uses a transformer based approach to collaborative and content-based filtering, is reviewed in terms of its design choices, architecture and evaluation. The model is then transferred to the domain of E-Learning based on two different use-cases. The first use cases will focus on platforms providing video based courses, like Linked-In learning \cite{LinkedInLearningMit}, while the second aims at recommending exercises to students in order to offer personalized learning experiences for students.

    \section{Sequential Content Recommendation}\label{sec:seq_recom}
    Traditional content recommendation systems usually observe user interactions as a set of independent and unrelated data points. These systems then compute or form a hidden representation in order to model user interests, which can then be used to predict which items may be relevant for the given user. If an item is considered relevant, it gets recommended. This modeling technique models a user's \textit{general} preferences and interests \cite{wangSequentialRecommenderSystems2019}. But, this is insufficient modelling, as user preferences change over time \cite{wangSequentialRecommenderSystems2019}! For example, let Alice be a user whose general interests reflect romantic films, such as Titanic, Romeo \& Juliet or \enquote{me before you} and who recently got into the Marvel Universe, and started watching Movies like \enquote{Spider-Man}. In addition, Alice is now really interested in following up with that series. Alice's movie history contains a total of 10 movies, 9 romantic movies and one Spider-Man movie, with the latter being the most recently watched. A traditional content recommendation system would observe Alice's movie history and model her interests as consisting of 90\% romantic films and 10\% Marvel. As a result, the recommendation system would assign romantic films a higher relevance score than a movie that is similar to Spider-Man, leading to unsatisfying recommendations for Alice's \textit{current} interests. Sequential Content Recommendation aims to solve this problem by observing user-interactions as a sequence. Thus, these models not only consider the items in the user history, but also the temporal aspect given by the order in which the items occur \cite{wangSequentialRecommenderSystems2019}. This ordering implies that more recent interactions are more relevant for recommending the next item, but at the same time also covers a user's general interest. As a result, Sequential Recommendation models are able to make accurate recommendations at any point in time, that also reflect temporary spikes of interests, while at the same time being able to recommend content that the user may generally be interested in. By choosing sequences as their data model, these models also gain a lot of flexibility in terms of the use cases they are able to cover. Because Sequential Recommendation models do not predict the relevance of items directly, but predict user-interaction probabilities at a given time-step, they are able to not only make recommendations for the present, but also for the future \cite{wangSequentialRecommenderSystems2019}. This allows these models to predict sequences of items, which can be used to craft recommendation series. E.g. a movie recommendation system can then recommend a complete series of movies which fit to Alice's interest in Marvel films, by predicting not only the next movie the user is likely to interact with but the next $n$ movies. These reasons, render Sequential Recommendation models theoretically superior to traditional recommendation models in terms of content recommendation. \\
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=0.6\textwidth]{images/rnn_seq.pdf}
        \caption{Sequential Content Recommendation with RNNs \cite{yuDynamicRecurrentModel2016}}
        \label{fig:seqRNN}
    \end{figure}
    A common approach to realizing Sequential Recommendation models is by using Recurrent Neural Networks (RNNs), such as Long-Short-Term-Memory (LSTMs) or Gated-Recurrent-Units (GRUs), as depicted in Figure \ref{fig:seqRNN}. The RNN gets the sequence of user-interactions or items as input, in this case movies, and encodes them into a fixed length vector representation, which gets updated at every time-step in the sequence. The model then predicts the interaction probabilities or rating scores for every item which may be recommended at the next time step \cite{yuDynamicRecurrentModel2016}. An example, for such an application can be found in Fung Yu et al. DREAM model \cite{yuDynamicRecurrentModel2016}. However, these models suffer from common RNN problems, such as catastrophic forgetting, vanishing gradients and uni-directionality, as well as their inefficiency when dealing with longer sequences. This motivates the use of transformer based models, more specifically HybridBERT4Rec, which allows to use a sequence based approach to content recommendation without the downsides of RNNs \cite{channarongHybridBERT4RecHybridContentBased2022}.

    \FloatBarrier

    \section{HybridBERT4Rec}
    \begin{figure}[ht!]
            \centering
            \includegraphics[width=0.6\textwidth]{images/hybridBERT4Rec_high_level.pdf}
            \caption{High level overview of HybridBERT4Recs Architecture. \cite{channarongHybridBERT4RecHybridContentBased2022}}
            \label{fig:highlevel}
        \end{figure}
        HybridBERT4Rec is a hybrid recommendation model, which was originally developed by Chanapa Channarong et al. \cite{channarongHybridBERT4RecHybridContentBased2022} on a movie recommendation task \cite{channarongHybridBERT4RecHybridContentBased2022}. It uses a combination of Collaborative Filtering (CF) and Content Based Filtering (CBF) methods, in order to predict a relevance score for a given target item.
        As shown in Figure \ref{fig:highlevel}, it consists of three main parts:
        \begin{enumerate}
            \item CBF-BERT4Rec: Models Content Based Filtering
            \item CF-BERT4Rec: Models Collaborative Filtering
            \item Prediction layer: Combines both approaches and predicts the final relevance score $\hat{r}_{u,v}$
        \end{enumerate}
        Both the CBF- and CF-Part of the model build upon HybridBERT4Recs predecessor BERT4Rec, and use the exact same architecture, while working with different inputs, in order to model their respective filtering techniques.

        \subsection{BERT4Rec}\label{seq:bert4rec}
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=0.6\textwidth]{images/BERT4Rec.pdf}
            \caption{BERT4Rec Architecture, taking item embeddings $v_t^u$ from user $u$'s history as input and predicts the next item $v_m^u$, u is likely to interact with \cite{sunBERT4RecSequentialRecommendation2019}.}
            \label{fig:bert4rec}
        \end{figure}
        BERT4Rec is a content recommendation model, which is based on the Bidirectional Encoder Representations from Transformers (BERT) model in order to facilitate Content Based Filtering. It has been developed in order to predict the next item a user is likely to interact with from a sequence of item embeddings from a user's interaction history. As depicted in Figure \ref{fig:bert4rec} The model consists of a learned positional embedding layer, an unmodified BERT transformer and a projection layer. In order to train BERT4Rec, Fei Sun et al. \cite{sunBERT4RecSequentialRecommendation2019} applied Masked Language Modelling, a common training technique from Natural Language Processing and transferred it to the domain of recommendation models. As a result, during training, one or more items in the input sequence are masked at random and replaced with a special \texttt{[mask]} token. Then, the learned positional embeddings are added to the item embeddings, and the sequence gets passed on to the standard BERT transformer. The resulting hidden representation, of the masked item(s) is then passed through the prediction layer, which consists of a two layer feed forward neural network with GELU activations and a softmax layer, as given by equation \ref{eq:pred_bert4rec}. This layer then produces an output distribution over the target items the model is supposed to rank.
        \begin{equation}\label{eq:pred_bert4rec}
            P(v) = \mathrm{softmax}(\texttt{GELU}(h_t^LW_p+b_p)E_T + b_O) \text{\cite{sunBERT4RecSequentialRecommendation2019}}
        \end{equation}
        In Equation \ref{eq:pred_bert4rec}, $h_t^L$ marks the hidden representation of the masked token, $W_p$ is the weight matrix of the linear layer, $b_p$ and $b_O$ are bias terms and $E_T$ is the item embedding matrix, which is also used to convert the items in the input sequence to item embeddings. The embedding matrix was reused in order to alleviate overfitting and reduce model size \cite{sunBERT4RecSequentialRecommendation2019}. \\
        This training objective allows the transformer to learn strong and meaningful item representations from their contexts. In the domain of recommendation models, this translates to learning how to construct the item representation of the next optimal item a user would want to interact with from the user's history. The prediction layer then essentially calculates similarity scores between this optimal item representation and the target items.\\
        Despite its upsides, using BERT4Rec in a standalone manner, still comes with a limitation. As the prediction is solely based on extracting user historical patterns which can be seen as characteristics the user favors, the model can't recommend items from categories that aren't included in the user history already. In other words, it can't help a user discover new content, which is a general downside of using CBF in a standalone setting \cite{channarongHybridBERT4RecHybridContentBased2022}. HybridBERT4Rec overcomes this issue by taking a hybrid approach to content recommendation by not only focusing on CBF but also using Collaborative Filtering techniques. But, before presenting how HybridBERT4Rec achieves Collaborative Filtering, the usage of BERT4Rec is put into context by laying out how HybridBERT4Rec achieves CBF using BERT4Rec in the following subsection.

        \subsection{CBF-BERT4Rec}
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=0.6\textwidth]{images/CBF-HybridBERT4Rec.pdf}
            \caption{CBF-HybridBERT4Rec Architecture, taking item embeddings from a user $u$ history as input and predicts a \enquote{target user profile $\overrightarrow{R_{u,v}}$} \cite{channarongHybridBERT4RecHybridContentBased2022}.}
            \label{fig:cbf-arch}
        \end{figure}
        As laid out earlier, the responsibility of CBF-BERT4Rec is to realize Content Based Filtering. In other words, it aims at extracting the target user representation, which describes the users preferences and interests. As shown in Figure \ref{fig:cbf-arch}, it achieves this by deploying BERT4Rec directly without any modifications. The input to the model is then given by the sequence of items in the target users history in chronological order. Then random item(s) are masked during the training process, during inference, the \texttt{[mask]} token is appended to the sequence and the model calculates the hidden representation for the masked token. This representation is then passed through the projection layer, as described earlier. The resulting distribution is then a distribution of all items over the \enquote{optimal item}, expressed as the interaction probability of the target user with all items. Chanapa Channarong et al. \cite{channarongHybridBERT4RecHybridContentBased2022} call this distribution the \enquote{target user profile $\overrightarrow{R_{u,v}}$}
        \FloatBarrier

        \subsection{CF-BERT4Rec}\label{sec:cf_bert4rec}
        In order to overcome the aforementioned limitations of only using CBF, HybridBERT4Rec also uses CF techniques. Implementing CF is the main responsibility of the CF-BERT4Rec part of HybridBERT4Rec. CF-BERT4Rec achieves collaborative filtering by constructing the representation of a target item based on the target user and its set of neighbors. As shown in Figure \ref{fig:cf-arch}, it also deploys BERT4Rec unmodified similar to CBF-BERT4Rec, but it uses completely different data. The input to CF-BERT4Rec is constructed by creating a sequence of all users who have interacted with the target item in chronological (in the case of movies, this is equivalent to all users who have rated the target movie). This may or may not include the target user. Again during inference, the \texttt{[mask]} token is appended to the sequence, and it is passed through BERT4Rec. The model will then construct a representation of the target item, reflecting the \enquote{optimal user} for this item, based on the neighboring users in the user sequence, which is passed on to the prediction layer. The prediction layer then yields a distribution of all neighboring users over the \enquote{optimal user}, expressed as user-similarity probabilities between the neighboring users and the target user, which is also called the \enquote{target item profile $\overrightarrow{R_{v,u}}$} \cite{channarongHybridBERT4RecHybridContentBased2022}.
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=0.6\textwidth]{images/CF-HybridBERT4Rec.pdf}
            \caption{CF-HybridBERT4Rec Architecture, taking user embeddings from all users that have rated the target item $v$ as input and predicts the \enquote{target item profile $\overrightarrow{R_{v,u}}$} \cite{channarongHybridBERT4RecHybridContentBased2022}.}
            \label{fig:cf-arch}
        \end{figure} \\
        This approach to collaborative filtering is quite unusual, as modeling the \textit{set} of neighbors as a sequence is questionable. The argument that the set of neighbors change over time and some might be more important than others does not hold in the same way as with content based filtering in collaborative filtering. Even though a users preferences might change overtime, and thus his current interests might not match with his past interests anymore, and he might thus not be a close neighbor anymore, his inclusion in the set of neighbors with an equal weighting is still valid. The reason for this is, that the primary goal of the inclusion of Collaborative Filtering is to enable \textit{exploration}. The recommender system is supposed to help the user explore new content by sacrificing the overall precision of the recommendations. Thus, the user who has moved from his past interests, is still as important as before, as the target user might be interested in following this user's direction as the system might not be aware of a specific interest of the target user. Because of that, the inclusion of a transformer based model in this case is questionable, as collaborative filtering in general only requires the calculation of user-user similarities between neighbors and the target user \cite{channarongHybridBERT4RecHybridContentBased2022}. As a result, the collaborative filtering part could have been implemented with a smaller and more efficient model, than with BERT4Rec. The authors also don't provide much reasoning as to why the use of a transformer based sequence recommendation model is beneficial for collaborative filtering \cite{channarongHybridBERT4RecHybridContentBased2022}.

        \subsection{Prediction Layer}
        % \begin{figure}[ht!]
        %     \centering
        %     \includegraphics[width=0.5\textwidth]{images/Prediction_Layer.pdf}
        %     \caption{Schematic of HybridBERT4Recs Prediction layer, which uses a generalization of Matrix Factorization based on Neural Networks with Sigmoid activations to predict the rating $\hat{r}_{u,v}$ user $u$ would assign to item $v$ \cite{channarongHybridBERT4RecHybridContentBased2022}.}
        %     \label{fig:pred_layer}
        % \end{figure}
        The last layer in HybridBERT4Rec is the Prediction Layer. It combines the target item profile $\overrightarrow{R_{v,u}}$ from the CF-part with the target user profile $\overrightarrow{R_{u,v}}$ from the CBF-part of the model through Generalized Matrix Factorization (GMF), in order to predict a final relevance score $\hat{r}_{u,v}$, which target user $u$ would assign to the target item $v$. The computation performed by this layer is given by Equation \ref{eq:pred_layer}, where $\odot$ denotes the element-wise product of both vectors \cite{channarongHybridBERT4RecHybridContentBased2022}.
        \begin{equation}\label{eq:pred_layer}
            \hat{r}_{u,v} = \sigma(WR(u,v) + b), \text{ with }
            R(u,v) = R_{uv} \odot R_{vu}
        \end{equation}
        In contrast to traditional Matrix Factorization, generalized matrix factorization is based on neural networks with sigmoid activations, which are trained with a log-loss. This allows the model to learn the interaction function between the user- and item profile from data. This grants the model the ability to express a form of Matrix Factorization that isn't uniform and non-linear. In other words, it is able to assign different weights to different latent dimensions of the user-item vector $R(u,v)$ and is able to model non-linear and more complex structures than traditional Matrix Factorization \cite{heNeuralCollaborativeFiltering2017}.

        \subsection{Strengths \& Weaknesses}\label{sec:str_weak}
        This transformer based architecture comes with several strengths:
        \begin{enumerate}
            \item \textbf{Highly parallelizable:} The model can be efficiently parallelized in several ways. First, it inherits the sequential in depth characteristics of transformer models. This means that the models internal computations can be efficiently parallelized on a per-layer basis, as the computation for time step $t$ at layer $l$ is independent of the result of the computation for time step $t+1$ or $t-1$ at layer $l$.
            \item \textbf{Bi-directionality:} Because HybridBERT4Rec is based on BERT, it inherits BERTs Bi-directionality. This allows the model to compute more expressive and meaningful representations of items, as these representations are not only dependent on past contents ($t < t_{present}$) but also on future ($t > t_{present}$) contents, providing a more sophisticated and information rich context for each token in the input sequence.
            \item \textbf{Sequential modelling:} It inherits the strengths of sequential content recommendation models, as explained in Section \ref{sec:seq_recom}. However, as layed out in Section \ref{sec:cf_bert4rec}, the use of a sequential approach to Collaborative Filtering remains questionable.
            \item \textbf{Independent Execution \& Caching:} HybridBERT4Recs CF- and CBF-part can be executed independent of each other, as no data flow is required between both parts. If this is combined with the ability to cache the target item- and user- profiles, then the model allows for dynamic profile calculations whenever needed. For example, it is only necessary to calculate the target user profile once for each item and similarly, the target item profile once for each user, as long as there is no update to either of them. If an update to one of them occurs, for example user $u$ watches a movie, and it is appended to his history, then \textit{only} the target item profile for user $u$ needs to be updated. There is no need to run the model for every user and every item again. At recommendation time, the cacheability of the user- and item-profiles also reduces the models time and hardware requirements, as only the comparatively small and shallow prediction-layer needs to be executed in order to retrieve new recommendations. Both, independent execution and caching grant the model a high flexibility in terms of model deployment and applications.
        \end{enumerate}
        Despite its numerous strengths, the model also includes some significant weaknesses:
        \begin{enumerate}
            \item \textbf{Limited Sequence Length:} Inheriting the characteristics of transformer models also means inheriting their weaknesses, in particular the limited sequence length. Because the per-layer complexity of the self-attention mechanisms of $O(n^2*d)$, where $n$ denotes the sequence length and $d$ the representation dimension, self-attention architectures scale badly in terms of sequence length \cite{vaswaniAttentionAllYou2017}. This combined with memory constraints of modern hardware limits the sequence length of any transformer based model. In the domain of recommendation systems, this translates to limiting the maximum length of user histories, and potential neighbors to form both the target user- and target item profiles. In the case of the movie recommendation example, used throughout this paper, it limits the length of a users watch history and the maximum number of ratings that can be taken into consideration in order to form a user's potential neighbors.
            \item \textbf{Hardware Requirements:} Because of HybridBERT4Recs hybrid nature, combining both Collaborative Filtering and Content Based Filtering, it also uses two seperate BERT based transformer models to model each approach. In the worst case, this translates to executing a transformer model for each of our users, another transformer model for each of our items and the prediction layer for each user-item combination, \textit{if intermediate results are cached}! If no caching is present, both transformer models and the prediction layer would have to be executed \textit{for every user and item combination}. In both cases, the model requires lots of processing power and memory in order to run. However, both processing and memory requirements do decrease significantly if the aforementioned optimization opportunities for dynamic recalculations, independent execution and caching are used. In addition, transformer models need comparatively large datasets if trained from scratch \cite{channarongHybridBERT4RecHybridContentBased2022,sunBERT4RecSequentialRecommendation2019,vaswaniAttentionAllYou2017}.
        \end{enumerate}

        \subsection{Performance \& Experiments}
        Chanapa Channarong et al. \cite{channarongHybridBERT4RecHybridContentBased2022} evaluated HybridBERT4Rec on three different datasets:
        \begin{itemize}
            \item MovieLens1M \cite{MovieLens1MDataset2015}: A movie recommendation dataset aimed at building and evaluating recommendation algorithms. It is composed of one million ratings from 6000 users on 4000 movies, with each user being responsible for at least 20 ratings.
            \item Yelp \cite{YelpDataset}: A dataset consisting of eight million ratings of restaurant and service business reviews, where each user created at least four ratings.
            \item GoodReads \cite{wanFineGrainedSpoilerDetection2019}: A book review dataset consisting of one million ratings, where each user has been responsible for at least 70 ratings.
        \end{itemize}
        As evaluation metrics, they adopted the Hit Ratio (HR) of the top $k$ predictions, which measures the ranking accuracy, and the Normalized Discounted Cumulative Gain (NDCG), which measures the recommendation list quality of the top $k$ positions. Along HybridBERT4Rec, they reported the performance of four additional models:
        \begin{itemize}
            \item Caser \cite{tangPersonalizedTopNSequential2018}: Caser is a unidirectional CBF approach using Convolutional Neural Networks (CNNs), which predicts the top-$N$ ranked items that a user will likely interact with.
            \item GRU4Rec \cite{hidasiSessionbasedRecommendationsRecurrent2016}: GRU4Rec is a unidirectional CBF approach using Recurrent Neural Networks (RNNs), more specifically Gated Recurrent Units, which predicts the next item embeddings at every time step.
            \item SAS4Rec \cite{kangSelfAttentiveSequentialRecommendation2018}: SAS4Rec is a unidirectional CBF approach, which uses a transformer-based architecture to predict the next item a user will interact with.
            \item BERT4Rec \cite{sunBERT4RecSequentialRecommendation2019}: As covered in Section \ref{seq:bert4rec}, it is a bidirectional transformer based architecture, which predicts the next item a user is likely to interact with. 
        \end{itemize}
        The results for NDCG@50 reported by Chanapa Channarong et al. \cite{channarongHybridBERT4RecHybridContentBased2022} are depicted in Figure \ref{fig:perfExp}.
        \begin{figure}[ht!]
            \centering
			\includegraphics[width=0.6\textwidth]{images/results.pdf}
			\caption{Performance comparison of different recommender models on three datasets as published by the authors of HybridBERT4Rec \cite{channarongHybridBERT4RecHybridContentBased2022}.}
            \label{fig:perfExp}
		\end{figure}
        In their experiments, HybridBERT4Rec outperforms all other models across all three datasets, with BERT4Rec being the second-best model and Caser performing the worst. The same result was obtained for the HR and all other values of $k$ for both metrics, hence these results haven't been directly reported in this paper again. For a detailed look at the numbers, please refer to Channarong et al. original paper \cite{channarongHybridBERT4RecHybridContentBased2022}. The results reported are not surprising, given that the \textit{Hybrid} bidirectional HybridBERT4Rec model was evaluated solely against unidirectional (except for BERT4Rec) \textit{Content Based Filtering} models. With that, the experiments are not representative in order to evaluate HybridBERT4Rec performance. The main takeaways presented by the experiments are that BERT4Recs bidirectional approach performs better than its unidirectional competitors and that the inclusion of Collaborative Filtering into Content Based Filtering models is effective and can increase recommendation performance. But, it remains unclear how HybridBERT4Rec performs in comparison to other hybrid recommendation models.\\
        In addition, the authors don't provide much information about how the data for training and testing has been partitioned for these experiments. They mention, that some authors had to be pruned from the datasets, because their histories were too short for model training, but other than that, no further information is provided. As a result, HybridBERT4Recs generalization performance also remains unknown, along with questions like: Does it suffer from the cold start problem? How does it handle new and unseen items / users? How does it handle domain transfer after training? Does it inherit the fine-tuning capabilities transformers are well known for \cite{radfordImprovingLanguageUnderstanding}? Without these questions answered the real world applicability of this model is unknown, as it is unclear how it would handle such a dynamic and fast-paced environment.

    \section{Applying HybridBERT4Rec in an E-Learning Environment}
    In this section, HybridBERT4Rec is going to be transferred into an E-Learning Environment. First, a trivial solution resolving around Video-content based E-Learning platforms such as Linked-In Learning \cite{LinkedInLearningMit} is presented. After that, a more involved setting, which reflects the use on an E-Learning platform like ILIAS \cite{Ilias}, is defined, followed by a discussion about how HybridBERT4Rec could be adapted and evaluated.

        \subsection{The Trivial Solution}
        \begin{figure}[ht!]
            \centering
			\includegraphics[width=0.4\textwidth]{images/linked_in_landing.pdf}
            \includegraphics[width=0.4\textwidth]{images/linked_in_course.pdf}
			\caption{Linked-In Learning landing-page and course overview \cite{LinkedInLearningMit}.}
            \label{fig:trivSol}
		\end{figure}
        As HybridBERT4Rec was originally developed and tested on the MovieLens1M \cite{MovieLens1MDataset2015} dataset, applying it in a video based setting which logs user watch histories and rating is trivial. An example for such an environment is Linked-In Learning \cite{LinkedInLearningMit}. As shown in Figure \ref{fig:trivSol}, Linked-In Learning offers video based learning courses, which can be \enquote{liked}, it also logs a history including which courses have been started and completed. In this setting, the history logged by the platform can be used directly to form the inputs for the CBF-BERT4Rec part of HybridBERT4Rec, similarly as with the original movie data. For the CF-Part, the \enquote{like} of a course can be seen as rating information. With that, every user who liked a course can be defined as a neighbor and be used in order to construct the user sequence for the CF-Part. As a result, the CF-Part can also be used directly, showing that HybridBERT4Rec can be applied to such a scenario without any necessary changes or adaptations, due to its similarity to movie recommendations.
    
        \subsection{Recommending Exercises to Create Personalized Learning Experiences for Students}
        However, if the E-Learning environment is more involved, HybridBERT4Rec can't be applied directly anymore without carefully defining its input and output data. To showcase such a scenario, an exercise recommendation task in an inverted classroom setting is considered. In this setting, students watch videos about different topics, which are clustered into Learning Objectives. After working through the material for each Learning Objective, students are asked to assign the Learning Objective a difficulty level. The recommendation algorithm should then recommend exercises to the student (user) which (presumably) fit their skill level. A more formal definition of this setting is shown in Figure \ref{fig:setting}.
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=0.7\textwidth]{images/setting.pdf}
            \caption{The Setting, consisting of a user collection $U$ and their histories $h(u)$, a collection of learning objectives $T$ and a collection of exercises $X$, which can be used to predict a ranking $R(u)$ for a given user $u$.}
            \label{fig:setting}
        \end{figure}
        Let $U$ represent the platform's user collection, encompassing every user (student) on the platform, alongside their exercise history $H(u)$. The collection $T$ includes Learning Objectives, storing each learning objective with its associated videos available on the platform. Similarly, the exercise collection $X$ comprises every exercise available on the platform. The difficulty rating $d$ a user $u \in U$ assigns to learning objective $t \in T$ is then given by $f:T \times U \rightarrow D, (t,u) \rightarrow d, \text{ with } D = \{1,2,3\}$. Here, each number in $D$ represents a difficulty level:
        \begin{itemize}
            \item $1$: Easy, the student $u$ encounters no issues solving complex tasks related to learning objective $t$,
            \item $2$: Medium, the student $u$ experiences some difficulty but has grasped the core principles assigned to learning objective $t$,
            \item $3$: Difficult, the student $u$ faces significant challenges in solving tasks related to learning objective $t$ and has not yet understood the core principles.
        \end{itemize}
        It is important to note that the learning objective collection and exercise collection exhibit a one-to-many relationship denoted by $R_{t,x}$. This relationship signifies, that for every exercise $x$ in the exercise collection, there must exist one learning objective $t$ in the learning objective collection, such that the tuple $(x,t)$ is in the relation $R_{t,x}$. In other words, every exercise has to be assigned to exactly one learning objective, whereas one learning objective can have multiple exercises assigned to it, this relation is then stored in $R_{t,x}$.\\
        The task of the recommendation model is then to process the available data and produce a ranking $R(u)$ for target user $u$, which encompasses different exercises, which fit the user's difficulty level for different learning objectives.
        
        \FloatBarrier
        \subsection{Model Adaption}
        % \begin{figure}[ht!]
        %     \centering
        %     \includegraphics[width=0.4\textwidth]{images/cbf.pdf}
        %     \includegraphics[width=0.4\textwidth]{images/CF_use_case.pdf}
        %     \caption{The adapted CBF-HybridBERT4Rec model on the left and the adapted CF-HybridBERT4Rec model on the right.}
        %     \label{fig:modelAdapt}
        % \end{figure}
        In order to adapt HybridBERT4Rec to work in the defined environment, no architecture changes are needed. But, the input sequences are not directly given by the use-case and have to be constructed from different parts of the available data. First, the input sequence for the CBF-Part of the model is constructed. For this, the exercise history of a user $u \in U$ has to be defined. Its definition is given in Equation \ref{eq:history}.
        \begin{equation}\label{eq:history}
            H(u) := (\{(x_i, t_j, s_k)| (x_i, t_j) \in R_{t,x}\}, \leq)
        \end{equation}
        The exercise history of a user $u$ consists of triples in the form of $(x_i, t_j, s_k)$, where $x_i$ denotes the completed exercise, $t_j$ its assigned learning objective, and $s_k$ the timestamp of the time of completion. For every triple included in the history, it holds that if one would construct a tuple with the exercise $x_i$ and the learning objective $t_i$, the tuple is included in the one-to-many relation $R_{t,x}$. Additionally, the history is ordered by the timestamp $s_k$, such that $s_{k-1} \leq s_k$. Using this definition, the input sequence $I(u)$ of user $u$ for the CBF-part is then given by Equation \ref{eq:input_sequence_cbf}.
        \begin{equation}\label{eq:input_sequence_cbf}
            I(u) := (\{x_i|(x_i, t_j, s_k) \in H(u)\}, \leq)
        \end{equation}
        It is constructed by extracting each completed exercise, which is present in the history $H(u)$ of user $u$, while preserving the order of the exercises into a new sequence $I(u)$. In more formal terms, for each exercise $x_i$ in the input sequence $I(u)$, it holds that a triple $(x_i, t_j, s_k)$ is included in $H(u)$ and the sequence is ordered by $s_k$ based on the triple included in $H(u)$, such that $s_{k-1} \leq s_k$. This results in an input sequence composed solely of exercises from the exercise collection, which the user has worked on, in ascending order. As a small note, it does not matter if the sequence is ordered in ascending or descending order, as long as it is ordered such that the neighborhood of $x_i$ is preserved. The reason for this are self-attentions ordering preserving properties \cite{vaswaniAttentionAllYou2017}. Orderings however, should not be mixed, as the positional encoding will otherwise lose its expressiveness.\\
        Next the user sequence for the CF-Part of the model will be constructed. As in Channarong et al. original proposition, the input is still a sequence of users. However, the users who are considered neighbors have to be carefully selected. Simply considering every user who assigned a difficulty rating to the target learning objective is not sufficient. Because, then users who rated the objective as easy and are able to complete more complex assignments would also be considered neighbors to users who have rated the learning objective as difficult. As a result, the target user may be deemed similar to another user who rated the target learning objective as easy, even though the target user has rated it as difficult. For example, if two users have the same courses, and their difficulty ratings are very close, or even similar for most courses, the model could consider both users as very similar, even though one rated the learning objective as easy and the other one rated it as difficult. This would result in the recommendation of too complex exercises for one and too simple ones for the other user. Because of that, a more restrictive filtering criteria is imposed.
        \begin{equation}\label{eq:cf}
            u \in N \iff d_{u, t} = d_{u_m, t} \text{\,} \wedge (x, t) \in \{(x,t)|(x,t,s_k) \in H(u)\}
        \end{equation}
        As given in Equation \ref{eq:cf}, a user is in the set of Neighbors $N$ for target user $u_m$ and the target learning objective $t$ \textit{if and only if}, the difficulty rating $d_{u,t}$, $u$ has assigned to t, is equal to the difficulty rating $d_{u_m, t}$, $u_m$ has assigned $t$ \textit{and} if the tuple $(x,t)$ of the target exercise $x$ and learning objective $t$ is included in the user's history. This filtering criteria restricts the set of neighbors to include only users who gave the same difficulty rating to the target learning objective as the target user. Additionally, it only considers users who have completed the specific exercise that the system aims to rank. In essence, this limits the set of users who can receive a high similarity probability to users who have the same level of difficulty with the same learning objective and who already studied for the target learning objective. This approach provides the model with the capability to recommend exercises that have proven beneficial for users facing similar difficulties, including exercises from other learning objectives.\\
        As a final step, the execution algorithm of the model needs to be adapted to the given setting. Algorithm \ref{alg:final_model} describes how the different parts of the model need to be executed, in order to retrieve the rating which the target user $u_m$ would assign to the target exercise and learning objective $(x,t)$.
        \begin{algorithm}[ht!]
            \caption{HybridBERT4Rec in an E-Learning Setting}
            \label{alg:final_model}
            \begin{algorithmic}[1]
                \ForAll{$u_m \in U$}
                    \State $r_{x,u_m} = \texttt{cbf\_bert4rec}(H(u_m))$
                    \ForAll{$(x,t) \in R_{t,x}$}
                        \State $r_{u, x} = \texttt{cf\_bert4rec}(u_m,t,x)$
                        \State $\hat{r}_{u,x} = \texttt{prediction\_layer}(r_{x,u}, r_{u,x})$
                    \EndFor
                \EndFor
            \end{algorithmic}
        \end{algorithm}
        First, for every user $u_m$ in the user collection $U$, the CBF-part \texttt{cbf\_bert4rec} needs to be executed resulting in the target user profile $r_{x,u_m}$. Then, for every tuple of target exercises and target learning objectives $(x,t)$ present in the Relation $R_{t,x}$ the CF-part \texttt{cf\_bert4rec} is executed, resulting in a target item profile $r_{u,x}$. Directly after that, the prediction layer is executed using both the target user and item profile in order to retrieve the final relevance score $\hat{r}_{u,x}$, which the target user $u_m$ would assign to the target exercise $x$. Because of the restrictive filtering objective, which is dependent on the target user $u_m$, the dynamic independent execution and caching strategies presented in Section \ref{sec:str_weak} can't be applied to the same extend. The complexity for a change in the user history is $O(x)$, with $x$ being the number of exercises in the exercise collection, because all target item profiles need to be recomputed, alongside the affected target user profile. For the movie recommendation task on the other hand the complexity is $O(1)$, as both parts can be executed independently during inference. The complexities for a change in the set of neighbors remain $O(1)$ for both tasks. As a result, the model can't be deployed as efficiently in this E-Learning setting as for movie recommendations.\\
        But, this model allows to compose different rankings with only one execution of Algorithm \ref{alg:final_model}. An overall ranking of exercises can be constructed, by sorting the exercises by their relevance scores independent of their assigned learning objectives. This could give students an overview about which topics and exercises should be prioritized in their studies. Additionally, a learning objective specific ranking can also be provided, by grouping the rated exercises by learning objective and sorting them by their relevance scores inside each group. This gives students the opportunity to pick a specific topic / learning objective that they want to study or improve.

        \FloatBarrier
        \subsection{Solving Evaluation}
        Evaluating the model in the given setting is difficult, as no binary or graded relevance annotations are available. Annotating the whole dataset is also infeasible, as this would require $U \times T \times X$ relevance annotations. Because, annotations are needed for every user, learning objective and exercise combination, if the annotations should also reflect the relevance of exercises for a learning objective which they are not related to, e.g. exercises from statistics might be helpful for understanding the Bayes rule. If this should not be reflected in the dataset, then $U \times X$ relevance annotations would be needed. Still, this is infeasible for large collections. In order to reduce the annotation workload, a method called pooling can be used \cite{suarezInformationRetrievalWeb2022}. The fundamental idea behind pooling, is that for most queries, in this case user-learning objective combinations, only a tiny fraction $N << X$ of exercises is actually relevant. An ideal recommendation system would rank said exercises at the top of the ranking \cite{suarezInformationRetrievalWeb2022}. Because of that, it can be sufficient to annotate only the top $n$ results of every ranking. As a result, only $U \times T \times N$ or $U \times N$ annotations are needed. Using the resulting test set, common metrics for recommendation systems can be computed, such as the P@k (Precision@k), R@k (Recall@k), NDCG, AP (Average Precision), MAP (Mean Average Precision) etc. However, a shortcoming of such an approach is, that it is not given that all relevant documents are included in the top $n$ positions of a ranking. As a result, it is possible, that relevant documents aren't annotated and are not considered in the evaluation. Thus, this method only provides an approximation of the recommendation models performance \cite{suarezInformationRetrievalWeb2022}. Nevertheless, using pooling marks a great balance between annotation work and evaluation accuracy if configured well.
         
    \section{Conclusion}
    In this paper, a thorough review of HybridBERT4Rec in an E-Learning for personalized learning experiences for students has been conducted. First, HybridBERT4Rec, along with its core concepts have been presented. Followed by a discussion of its architecture, design choices and evaluation strategy. During this discussion, design choices, such as the usage of sequential recommendation techniques for Collaborative Filtering have been questioned. Unfortunately, it was not possible to find convincing arguments to back up this decision. However, the model still showed great potential on an architectural level because it uses sequential modeling and is optimizable through techniques like dynamic independent execution and caching. It also inherits positive properties from its foundation models, like Bi-directionality and highly parallelizability, allowing for efficient training and learning expressive embeddings. But, the model also showed some weaknesses, namely the limited sequence length and large hardware requirements. The evaluation conducted in the original proposition of HybridBERT4Rec was also deemed insufficient. The baseline models were chosen, such that they all impose significant disadvantages to the task compared to HybridBERT4Rec, as no hybrid recommendation model has been evaluated. In addition, the partitioning of the used dataset is unclear and many questions in regard to the models real world applicability have not been mentioned or answered. As a result, HybridBERT4Recs real world applicability remains an unknown quantity.\\
    After the thorough discussion, HybridBERT4Rec has been transferred into the domain of E-Learning. First, a trivial solution using the example of Linked-In learning has been presented. Then, a more complex scenario has been constructed around the task of recommending exercises to students in order to create personalized learning experiences for students. In this environment, students were able to rate learning objectives with a difficulty level ranging from easy to difficult. Based on this difficulty rating, the recommendation model is then supposed to recommend exercises to the student, which presumably fit their skill level. Adapting HybridBERT4Rec to this environment proved challenging, despite the fact that no changes in the model's architecture were necessary. But, the individual inputs needed to be carefully defined, in order to ensure that the model is working as intended and maintains its flexibility in terms of item (exercise) recommendation. Especially the construction of the inputs for the collaborative filtering part proved to be difficult, as the set of users who are considered neighbors have to be carefully chosen. If chosen too broadly, the model could deem users as similar, even though they assigned different difficulty ratings to the current learning objective, leading to the recommendation of too complex exercises to the target user. If chosen too narrow, the inclusion of collaborative filtering into the model could become unnecessary, as the neighbors could become too similar to the target user, leading the model to recommend the same exercises as without collaborative filtering. In order to find a balance, neighbors were chosen based on the difficulty level assigned to the target learning objective and based on a user's history.\\
    After that, the final algorithm of HybridBERT4Rec in the E-Learning setting was presented, followed up by a recommendation on how to evaluate HybridBERT4Rec. Evaluating the model in the given setting also posed a challenge, as the number of necessary annotations was deemed infeasible. In order to solve this, the pooling technique was recommended, which greatly reduces the amount of necessary annotations.\\
    In conclusion, HybridBERT4Rec showed great potential on an architectural level and proofed to be transferable to different E-Learning use-cases. However, its unsatisfactory evaluation and some questionable design choices leaves the model in an unusable state for real world applications without further testing and evaluation. As a result, future work should focus on evaluation and testing of the models design choices, performance on downstream tasks and real world applicability.
%TC:ignore
%\clearpage %add new page for references
    \singlespacing
    \emergencystretch 3em
    \hfuzz 1px
    \printbibliography[heading=bibnumbered]

% \clearpage
% \begin{appendices}

% \section{Here go any appendices!}

% \end{appendices}

%TC:endignore
\end{document}